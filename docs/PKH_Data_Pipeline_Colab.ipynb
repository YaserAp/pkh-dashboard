{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PKH Dashboard - Data Processing Pipeline (Colab)\n",
        "\n",
        "Notebook ini menjelaskan **tahapan pengolahan data dari awal hingga menjadi tabel processed** seperti yang dipakai dashboard saat ini.\n",
        "\n",
        "## Input file yang dibutuhkan (nama file harus sama)\n",
        "- `bps-od_17058_persentase_penduduk_miskin__kabupatenkota_data.csv`\n",
        "- `dinsos-od_20731_jml_penerima_bantuan_program_keluarga_harapan_pkh__v2_data.csv`\n",
        "- `bps-od_16425_jumlah_penduduk_miskin_berdasarkan_kabupatenkota_data.csv`\n",
        "- `bps-od_17112_jumlah_penduduk_miskin_berdasarkan_daerah_v9_data.csv`\n",
        "\n",
        "Output (processed):\n",
        "- `dim_kabupaten.csv`\n",
        "- `fact_pkh.csv`\n",
        "- `fact_kemiskinan_persen.csv`\n",
        "- `fact_kemiskinan_abs.csv`\n",
        "- `fact_kemiskinan_kategori.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Setup lokasi kerja\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path(\"/content\")\n",
        "RAW_DIR = BASE_DIR / \"data\" / \"raw\"\n",
        "PROCESSED_DIR = BASE_DIR / \"data\" / \"processed\"\n",
        "\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"RAW_DIR:\", RAW_DIR)\n",
        "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload file CSV\n",
        "Gunakan `files.upload()` lalu pindahkan file ke folder `RAW_DIR`.\n",
        "Pastikan **nama file sama persis** dengan daftar di atas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name in uploaded.keys():\n",
        "    target = RAW_DIR / name\n",
        "    with open(target, \"wb\") as f:\n",
        "        f.write(uploaded[name])\n",
        "\n",
        "print(\"Files in RAW_DIR:\")\n",
        "for path in RAW_DIR.iterdir():\n",
        "    print(\"-\", path.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load & validasi kolom\n",
        "Validasi memastikan setiap file memiliki kolom wajib sesuai pipeline di backend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATASET_FILES = {\n",
        "    \"kemiskinan_persen\": \"bps-od_17058_persentase_penduduk_miskin__kabupatenkota_data.csv\",\n",
        "    \"pkh\": \"dinsos-od_20731_jml_penerima_bantuan_program_keluarga_harapan_pkh__v2_data.csv\",\n",
        "    \"kemiskinan_abs\": \"bps-od_16425_jumlah_penduduk_miskin_berdasarkan_kabupatenkota_data.csv\",\n",
        "    \"kemiskinan_kategori\": \"bps-od_17112_jumlah_penduduk_miskin_berdasarkan_daerah_v9_data.csv\",\n",
        "}\n",
        "\n",
        "REQUIRED_COLUMNS = {\n",
        "    \"kemiskinan_persen\": {\n",
        "        \"kode_provinsi\",\n",
        "        \"nama_provinsi\",\n",
        "        \"kode_kabupaten_kota\",\n",
        "        \"nama_kabupaten_kota\",\n",
        "        \"persentase_penduduk_miskin\",\n",
        "        \"tahun\",\n",
        "    },\n",
        "    \"pkh\": {\n",
        "        \"kode_provinsi\",\n",
        "        \"nama_provinsi\",\n",
        "        \"kode_kabupaten_kota\",\n",
        "        \"nama_kabupaten_kota\",\n",
        "        \"jumlah_penerima_manfaat\",\n",
        "        \"tahun\",\n",
        "    },\n",
        "    \"kemiskinan_abs\": {\n",
        "        \"kode_provinsi\",\n",
        "        \"nama_provinsi\",\n",
        "        \"kode_kabupaten_kota\",\n",
        "        \"nama_kabupaten_kota\",\n",
        "        \"jumlah_penduduk_miskin\",\n",
        "        \"tahun\",\n",
        "    },\n",
        "    \"kemiskinan_kategori\": {\n",
        "        \"kode_provinsi\",\n",
        "        \"nama_provinsi\",\n",
        "        \"kategori_daerah\",\n",
        "        \"periode_bulan\",\n",
        "        \"jumlah_penduduk\",\n",
        "        \"tahun\",\n",
        "    },\n",
        "}\n",
        "\n",
        "datasets = {}\n",
        "for key, filename in DATASET_FILES.items():\n",
        "    path = RAW_DIR / filename\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Missing dataset: {path}\")\n",
        "    datasets[key] = pd.read_csv(path)\n",
        "\n",
        "def validate_dataset(df, key):\n",
        "    required = REQUIRED_COLUMNS[key]\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns for {key}: {sorted(missing)}\")\n",
        "\n",
        "for key, df in datasets.items():\n",
        "    validate_dataset(df, key)\n",
        "    print(key, \"rows:\", len(df), \"cols:\", len(df.columns))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalisasi teks + filter Jawa Barat\n",
        "Samakan penulisan nama kabupaten/kota & provinsi, lalu filter hanya provinsi Jawa Barat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "PROV_CODE_JABAR = 32\n",
        "PROV_NAME_JABAR = \"JAWA BARAT\"\n",
        "\n",
        "def normalize_common(df):\n",
        "    df = df.copy()\n",
        "    if \"nama_kabupaten_kota\" in df.columns:\n",
        "        df[\"nama_kabupaten_kota\"] = (\n",
        "            df[\"nama_kabupaten_kota\"].astype(str).str.upper().str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "        )\n",
        "    if \"nama_provinsi\" in df.columns:\n",
        "        df[\"nama_provinsi\"] = df[\"nama_provinsi\"].astype(str).str.upper().str.strip()\n",
        "    return df\n",
        "\n",
        "def filter_jabar(df):\n",
        "    if \"kode_provinsi\" in df.columns:\n",
        "        df = df[df[\"kode_provinsi\"] == PROV_CODE_JABAR]\n",
        "    if \"nama_provinsi\" in df.columns:\n",
        "        df = df[df[\"nama_provinsi\"] == PROV_NAME_JABAR]\n",
        "    return df\n",
        "\n",
        "for key, df in datasets.items():\n",
        "    df = normalize_common(df)\n",
        "    df = filter_jabar(df)\n",
        "    datasets[key] = df\n",
        "\n",
        "for key, df in datasets.items():\n",
        "    print(key, \"rows after filter:\", len(df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Coerce numeric + filter tahun\n",
        "Pastikan kolom numerik dalam format angka dan batasi tahun (default 2017-2024)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "START_YEAR = 2017\n",
        "END_YEAR = 2024\n",
        "\n",
        "def coerce_numeric(df, cols):\n",
        "    df = df.copy()\n",
        "    for col in cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "persen = coerce_numeric(datasets[\"kemiskinan_persen\"], [\"kode_kabupaten_kota\", \"tahun\", \"persentase_penduduk_miskin\"])\n",
        "pkh = coerce_numeric(datasets[\"pkh\"], [\"kode_kabupaten_kota\", \"tahun\", \"jumlah_penerima_manfaat\"])\n",
        "abs_miskin = coerce_numeric(datasets[\"kemiskinan_abs\"], [\"kode_kabupaten_kota\", \"tahun\", \"jumlah_penduduk_miskin\"])\n",
        "kategori = coerce_numeric(datasets[\"kemiskinan_kategori\"], [\"tahun\", \"jumlah_penduduk\"])\n",
        "\n",
        "persen = persen[(persen[\"tahun\"] >= START_YEAR) & (persen[\"tahun\"] <= END_YEAR)]\n",
        "pkh = pkh[(pkh[\"tahun\"] >= START_YEAR) & (pkh[\"tahun\"] <= END_YEAR)]\n",
        "abs_miskin = abs_miskin[(abs_miskin[\"tahun\"] >= START_YEAR) & (abs_miskin[\"tahun\"] <= END_YEAR)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build tabel dimensi & fakta + simpan\n",
        "Menghasilkan tabel processed sesuai struktur dashboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "dim_kabupaten = (\n",
        "    pd.concat(\n",
        "        [\n",
        "            persen[[\"kode_kabupaten_kota\", \"nama_kabupaten_kota\", \"kode_provinsi\", \"nama_provinsi\"]],\n",
        "            pkh[[\"kode_kabupaten_kota\", \"nama_kabupaten_kota\", \"kode_provinsi\", \"nama_provinsi\"]],\n",
        "        ],\n",
        "        ignore_index=True,\n",
        "    )\n",
        "    .dropna(subset=[\"kode_kabupaten_kota\"])\n",
        "    .drop_duplicates(subset=[\"kode_kabupaten_kota\"])\n",
        "    .sort_values(\"nama_kabupaten_kota\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "fact_pkh = pkh[[\"tahun\", \"kode_kabupaten_kota\", \"nama_kabupaten_kota\", \"jumlah_penerima_manfaat\"]]\n",
        "fact_persen = persen[[\"tahun\", \"kode_kabupaten_kota\", \"nama_kabupaten_kota\", \"persentase_penduduk_miskin\"]]\n",
        "fact_abs = abs_miskin[[\"tahun\", \"kode_kabupaten_kota\", \"nama_kabupaten_kota\", \"jumlah_penduduk_miskin\"]]\n",
        "fact_kategori = kategori[[\"tahun\", \"periode_bulan\", \"kategori_daerah\", \"jumlah_penduduk\"]]\n",
        "\n",
        "dim_kabupaten.to_csv(PROCESSED_DIR / \"dim_kabupaten.csv\", index=False)\n",
        "fact_pkh.to_csv(PROCESSED_DIR / \"fact_pkh.csv\", index=False)\n",
        "fact_persen.to_csv(PROCESSED_DIR / \"fact_kemiskinan_persen.csv\", index=False)\n",
        "fact_abs.to_csv(PROCESSED_DIR / \"fact_kemiskinan_abs.csv\", index=False)\n",
        "fact_kategori.to_csv(PROCESSED_DIR / \"fact_kemiskinan_kategori.csv\", index=False)\n",
        "\n",
        "print(\"Saved to:\", PROCESSED_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick checks\n",
        "Cek rentang tahun dan jumlah baris untuk memastikan proses berhasil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def show_stats(path, year_col=\"tahun\"):\n",
        "    df = pd.read_csv(path)\n",
        "    years = df[year_col].dropna().astype(int)\n",
        "    print(path.name, \"rows:\", len(df), \"years:\", years.min(), \"-\", years.max())\n",
        "\n",
        "show_stats(PROCESSED_DIR / \"fact_pkh.csv\")\n",
        "show_stats(PROCESSED_DIR / \"fact_kemiskinan_abs.csv\")\n",
        "show_stats(PROCESSED_DIR / \"fact_kemiskinan_persen.csv\")\n",
        "show_stats(PROCESSED_DIR / \"fact_kemiskinan_kategori.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export / download hasil\n",
        "Jika ingin download ke lokal:\n",
        "```\n",
        "from google.colab import files\n",
        "files.download('/content/data/processed/fact_pkh.csv')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediksi 5 Tahun ke Depan\n",
        "Bagian ini membuat **prediksi 5 tahun** untuk PKH, kemiskinan absolut, dan kemiskinan persen.\n",
        "Metode: Holt-Winters (trend additive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "HORIZON = 5\n",
        "\n",
        "def forecast_series(values, years, horizon=5):\n",
        "    values = values.dropna().astype(float)\n",
        "    if len(values) < 2 or values.nunique() == 1:\n",
        "        return [float(values.iloc[-1])] * horizon\n",
        "    # Use a proper yearly index to avoid statsmodels warnings\n",
        "    series = values.copy()\n",
        "    series.index = pd.PeriodIndex(years.astype(int), freq=\"Y\")\n",
        "    model = ExponentialSmoothing(series, trend=\"add\", seasonal=None, initialization_method=\"estimated\")\n",
        "    fit = model.fit(optimized=True)\n",
        "    return [float(x) for x in fit.forecast(horizon)]\n",
        "\n",
        "def forecast_by_kabkota(df, value_col, horizon=5, clip_min=None, clip_max=None):\n",
        "    results = []\n",
        "    last_year = int(df[\"tahun\"].max())\n",
        "    for (kode, nama), group in df.groupby([\"kode_kabupaten_kota\", \"nama_kabupaten_kota\"]):\n",
        "        group = group.sort_values(\"tahun\")\n",
        "        preds = forecast_series(group[value_col], group[\"tahun\"], horizon)\n",
        "        for i, val in enumerate(preds, start=1):\n",
        "            if clip_min is not None:\n",
        "                val = max(clip_min, val)\n",
        "            if clip_max is not None:\n",
        "                val = min(clip_max, val)\n",
        "            results.append({\n",
        "                \"tahun\": last_year + i,\n",
        "                \"kode_kabupaten_kota\": int(kode),\n",
        "                \"nama_kabupaten_kota\": nama,\n",
        "                \"value\": float(val),\n",
        "            })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "pred_pkh = forecast_by_kabkota(fact_pkh, \"jumlah_penerima_manfaat\", HORIZON, clip_min=0.0)\n",
        "pred_abs = forecast_by_kabkota(fact_abs, \"jumlah_penduduk_miskin\", HORIZON, clip_min=0.0)\n",
        "pred_persen = forecast_by_kabkota(fact_persen, \"persentase_penduduk_miskin\", HORIZON, clip_min=0.0, clip_max=100.0)\n",
        "\n",
        "pred_pkh.to_csv(PROCESSED_DIR / \"pred_pkh.csv\", index=False)\n",
        "pred_abs.to_csv(PROCESSED_DIR / \"pred_kemiskinan_abs.csv\", index=False)\n",
        "pred_persen.to_csv(PROCESSED_DIR / \"pred_kemiskinan_persen.csv\", index=False)\n",
        "\n",
        "print(\"Prediksi tersimpan di\", PROCESSED_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualisasi Ringkas\n",
        "Visualisasi sederhana untuk melihat tren historis dan prediksi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def avg_by_year(df, value_col):\n",
        "    return df.groupby(\"tahun\", as_index=False)[value_col].mean()\n",
        "\n",
        "hist_pkh = avg_by_year(fact_pkh, \"jumlah_penerima_manfaat\")\n",
        "hist_abs = avg_by_year(fact_abs, \"jumlah_penduduk_miskin\")\n",
        "hist_persen = avg_by_year(fact_persen, \"persentase_penduduk_miskin\")\n",
        "\n",
        "pred_pkh_avg = pred_pkh.groupby(\"tahun\", as_index=False)[\"value\"].mean()\n",
        "pred_abs_avg = pred_abs.groupby(\"tahun\", as_index=False)[\"value\"].mean()\n",
        "pred_persen_avg = pred_persen.groupby(\"tahun\", as_index=False)[\"value\"].mean()\n",
        "\n",
        "def plot_history_forecast(hist_df, pred_df, title, ylabel):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(hist_df[\"tahun\"], hist_df.iloc[:,1], marker=\"o\", label=\"Aktual\")\n",
        "    plt.plot(pred_df[\"tahun\"], pred_df[\"value\"], marker=\"o\", label=\"Prediksi\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Tahun\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.2)\n",
        "    plt.show()\n",
        "\n",
        "plot_history_forecast(hist_pkh, pred_pkh_avg, \"PKH (Rata-rata)\", \"Penerima\")\n",
        "plot_history_forecast(hist_abs, pred_abs_avg, \"Kemiskinan Absolut (Rata-rata)\", \"Ribu orang\")\n",
        "plot_history_forecast(hist_persen, pred_persen_avg, \"Kemiskinan (%) Rata-rata\", \"%\")\n"
      ]
    }
    ,
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Perbandingan 3 Metode (Holt, ARIMA, Linear)\n",
        "Evaluasi sederhana memakai **2 tahun terakhir** sebagai data uji.\n",
        "Akurasi dirangkum dalam MAE/RMSE/MAPE dan skor 0-100 (100 - MAPE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "TEST_YEARS = 2\n",
        "METHODS = [\"holt\", \"arima\", \"linear\"]\n",
        "\n",
        "def forecast_series_arima(values, years, horizon=5):\n",
        "    values = values.dropna().astype(float)\n",
        "    if len(values) < 3 or values.nunique() == 1:\n",
        "        return [float(values.iloc[-1])] * horizon\n",
        "    series = values.copy()\n",
        "    series.index = pd.PeriodIndex(years.astype(int), freq=\"Y\")\n",
        "    model = ARIMA(series, order=(1, 1, 1))\n",
        "    fit = model.fit()\n",
        "    return [float(x) for x in fit.forecast(steps=horizon)]\n",
        "\n",
        "def forecast_series_linear(values, years, horizon=5):\n",
        "    values = values.dropna().astype(float)\n",
        "    if len(values) < 2 or values.nunique() == 1:\n",
        "        return [float(values.iloc[-1])] * horizon\n",
        "    x = np.arange(len(values))\n",
        "    coef = np.polyfit(x, values, 1)\n",
        "    steps = np.arange(len(values), len(values) + horizon)\n",
        "    return [float(v) for v in (coef[0] * steps + coef[1])]\n",
        "\n",
        "def predict_series(values, years, method, horizon):\n",
        "    if method == \"holt\":\n",
        "        return forecast_series(values, years, horizon)\n",
        "    if method == \"arima\":\n",
        "        return forecast_series_arima(values, years, horizon)\n",
        "    if method == \"linear\":\n",
        "        return forecast_series_linear(values, years, horizon)\n",
        "    return forecast_series(values, horizon)\n",
        "\n",
        "def evaluate_methods(df, value_col, test_years=2, clip_min=None, clip_max=None):\n",
        "    years = sorted(df[\"tahun\"].unique())\n",
        "    if len(years) <= test_years:\n",
        "        return pd.DataFrame()\n",
        "    train_end = years[-(test_years + 1)]\n",
        "    results = []\n",
        "    for method in METHODS:\n",
        "        all_rmse = []\n",
        "        all_mae = []\n",
        "        all_mape = []\n",
        "        for (_, _), group in df.groupby([\"kode_kabupaten_kota\", \"nama_kabupaten_kota\"]):\n",
        "            group = group.sort_values(\"tahun\")\n",
        "            train = group[group[\"tahun\"] <= train_end]\n",
        "            test = group[group[\"tahun\"] > train_end].head(test_years)\n",
        "            if len(train) < 3 or len(test) < test_years:\n",
        "                continue\n",
        "            actual = test[value_col].astype(float).values\n",
        "            preds = np.array(predict_series(train[value_col], train[\"tahun\"], method, test_years))\n",
        "            if clip_min is not None:\n",
        "                preds = np.maximum(preds, clip_min)\n",
        "            if clip_max is not None:\n",
        "                preds = np.minimum(preds, clip_max)\n",
        "            diff = preds - actual\n",
        "            rmse = np.sqrt(np.mean(diff**2))\n",
        "            mae = np.mean(np.abs(diff))\n",
        "            denom = np.where(actual == 0, 1.0, actual)\n",
        "            mape = np.mean(np.abs(diff) / denom) * 100\n",
        "            all_rmse.append(rmse)\n",
        "            all_mae.append(mae)\n",
        "            all_mape.append(mape)\n",
        "        if all_rmse:\n",
        "            rmse_mean = float(np.mean(all_rmse))\n",
        "            mae_mean = float(np.mean(all_mae))\n",
        "            mape_mean = float(np.mean(all_mape))\n",
        "            score = max(0.0, 100.0 - mape_mean)\n",
        "            results.append({\n",
        "                \"method\": method,\n",
        "                \"rmse\": rmse_mean,\n",
        "                \"mae\": mae_mean,\n",
        "                \"mape\": mape_mean,\n",
        "                \"score\": score,\n",
        "            })\n",
        "    return pd.DataFrame(results).sort_values(\"score\", ascending=False)\n",
        "\n",
        "compare_pkh = evaluate_methods(fact_pkh, \"jumlah_penerima_manfaat\", TEST_YEARS, clip_min=0.0)\n",
        "compare_abs = evaluate_methods(fact_abs, \"jumlah_penduduk_miskin\", TEST_YEARS, clip_min=0.0)\n",
        "compare_persen = evaluate_methods(fact_persen, \"persentase_penduduk_miskin\", TEST_YEARS, clip_min=0.0, clip_max=100.0)\n",
        "\n",
        "print(\"PKH:\\n\", compare_pkh)\n",
        "print(\"Kemiskinan_abs:\\n\", compare_abs)\n",
        "print(\"Kemiskinan%:\\n\", compare_persen)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualisasi per Kab/Kota (Top 10)\n",
        "Visualisasi hasil prediksi pada **tahun terakhir** untuk 10 kab/kota dengan nilai tertinggi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_top_kabkota(pred_df, title, unit_label, top_n=10):\n",
        "    last_year = pred_df[\"tahun\"].max()\n",
        "    top = pred_df[pred_df[\"tahun\"] == last_year].sort_values(\"value\", ascending=False).head(top_n)\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.barh(top[\"nama_kabupaten_kota\"], top[\"value\"])\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(f\"{title} (Top {top_n}) - Tahun {int(last_year)}\")\n",
        "    plt.xlabel(unit_label)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_top_kabkota(pred_pkh, \"Prediksi PKH\", \"Penerima\")\n",
        "plot_top_kabkota(pred_abs, \"Prediksi Kemiskinan Absolut\", \"Ribu orang\")\n",
        "plot_top_kabkota(pred_persen, \"Prediksi Kemiskinan (%)\", \"%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PKH_Data_Pipeline_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
